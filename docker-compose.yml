services:
  mlflow:
    container_name: mlflow
    image: ghcr.io/mlflow/mlflow:latest
    environment:
      MLFLOW_SERVER_ALLOWED_HOSTS: "127.0.0.1,127.0.0.1:5000,localhost,localhost:5000,mlflow,mlflow:5000"
      MLFLOW_SERVER_CORS_ALLOWED_ORIGINS: "http://127.0.0.1:*,http://localhost:*"
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:////mlflow/mlflow.db
      --serve-artifacts
      --artifacts-destination /mlflow/artifacts
    volumes:
      - mlflow_data:/mlflow
      - mlflow_artifacts:/mlflow/artifacts
    ports:
      - "5000:5000"
    networks:
      - app_net
    restart: unless-stopped

  backend:
    container_name: backend
    build:
      context: ./backend
      dockerfile: Dockerfile

    gpus: all

    ipc: host
    shm_size: "8gb"

    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
      MLFLOW_REGISTRY_URI: http://mlflow:5000
      MLFLOW_PUBLIC_URI:  http://localhost:5000

      CORS_ALLOWED_ORIGINS: http://localhost:3000

      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility

      APP_HOST: 0.0.0.0
      APP_PORT: 8000
    depends_on:
      - mlflow
    ports:
      - "8000:8000"
    networks:
      - app_net
    restart: unless-stopped

  front:
    container_name: front
    build:
      context: ./front
      dockerfile: Dockerfile
    # environment:
      # TODO: update backend uri if changed, for now it is http://localhost:8000
    depends_on:
      - backend
    ports:
      - "3000:80"
    networks:
      - app_net
    restart: unless-stopped

networks:
  app_net:
    driver: bridge

volumes:
  mlflow_data:
  mlflow_artifacts:

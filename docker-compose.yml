services:
  mlflow:
    container_name: mlflow
    image: ghcr.io/mlflow/mlflow:latest
    environment:
      MLFLOW_SERVER_ALLOWED_HOSTS: "127.0.0.1,127.0.0.1:5000,localhost,localhost:5000,mlflow,mlflow:5000"
      MLFLOW_SERVER_CORS_ALLOWED_ORIGINS: "http://127.0.0.1:*,http://localhost:*"
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:////mlflow/mlflow.db
      --serve-artifacts
      --artifacts-destination /mlflow/artifacts
    volumes:
      - mlflow_data:/mlflow
      - mlflow_artifacts:/mlflow/artifacts
    ports:
      - "5000:5000"
    networks:
      - app_net
    restart: unless-stopped

  backend:
    container_name: backend
    build:
      context: ./backend
      dockerfile: Dockerfile
    
    tty: true
    
    stdin_open: true
    
    gpus: all

    ipc: host
    shm_size: "8gb"

    environment:
      LOG_LEVEL: DEBUG
      MUTE_THIRD_PARTY_LOGS: "1"

      MLFLOW_TRACKING_URI: http://mlflow:5000
      MLFLOW_REGISTRY_URI: http://mlflow:5000
      MLFLOW_PUBLIC_URI:  http://localhost:5000
      
      CLEANUP_RUNS_INTERVAL: "60"
      CLEANUP_JOBS_INTERVAL: "60"
      JOBS_TTL: "7200"
      RUNS_INACTIVITY: "1800"


      # TODO: add later support for local executions, not only jupyter
      CORS_ALLOWED_ORIGINS: http://localhost:8888

      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility

      APP_HOST: 0.0.0.0
      APP_PORT: 8000
    depends_on:
      - mlflow
    ports:
      - "8000:8000"
    networks:
      - app_net
    restart: unless-stopped

networks:
  app_net:
    driver: bridge

volumes:
  mlflow_data:
  mlflow_artifacts:
